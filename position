import cv2
import numpy as np
from pupil_apriltags import Detector

# Define camera parameters after calibration
camera_fx = 624.9471386
camera_fy = 635.74083359
camera_cx = 321.90189406
camera_cy = 263.79474841

camera_matrix = np.array([[camera_fx, 0, camera_cx],
                      [0, camera_fy, camera_cy],
                      [0, 0, 1]])

distortion_coeffs = np.array([[-4.11082203e-01, 3.16018361e+00, 4.99088110e-03, -1.10638717e-02, -8.65431343e+00]])

# Define the dimensions of the FRC field in meters
field_width = 16.654 # In meters
field_height = 8.229 # In meters

# Define the tag size in meters
tag_size = 0.055 # In meters

# Initialize the AprilTag detector
detector = Detector(families='tag36h11',
                nthreads=1,
                quad_decimate=1.0,
                quad_sigma=0.0,
                refine_edges=1,
                decode_sharpening=0.25,
                debug=0)

cap = cv2.VideoCapture(0) # Open the camera
img = cv2.imread('2023.PNG')

while True:
   ret, frame = cap.read() # Capture frame from the camera
   gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # Convert the frame to grayscale

   tags = detector.detect(gray, estimate_tag_pose=True, camera_params=(camera_fx, camera_fy, camera_cx, camera_cy), tag_size=tag_size) # Detect AprilTags

   for tag in tags:
       distance = tag.pose_t[2] # Depth of the tag
       sidedist = tag.pose_t[0] # Right-left distance of the tag

       # Convert to meters
       metersidedist = sidedist
       meterdist = distance

       # Calculate the position of the tag in the camera frame
       tag_position = (250 + int(metersidedist * 100), int(meterdist * 100))

       # Determine the robot's position relative to the middle of the FRC field
       robot_x = (tag_position[0] - (frame.shape[1] // 2)) * (field_width / frame.shape[1])
       robot_y = (tag_position[1] - (frame.shape[0] // 2)) * (field_height / frame.shape[0])

       # Draw lines around the tag
       for idx in range(len(tag.corners)):
           cv2.line(frame, tuple(tag.corners[idx - 1, :].astype(int)),
                   tuple(tag.corners[idx, :].astype(int)), (0, 255, 0), 2)

       # Display the robot's position on the frame
       cv2.putText(frame, f"Robot Position: ({robot_x:.2f} m, {robot_y:.2f} m)", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
       cv2.circle(img,(robot_x,robot_y),5,(255,0,255),-1)
   cv2.imshow('AprilTag Detection', frame) # Display the frame
   cv2.imshow("filed", img)

   if cv2.waitKey(1) & 0xFF == ord('q'): # Exit the loop if 'q' is pressed
       break

cap.release() # Release the camera
cv2.destroyAllWindows() # Close all windows
